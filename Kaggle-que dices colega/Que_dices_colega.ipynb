{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "from skimage.io import imread\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el tama√±o de la imagen (125x125) y los paths\n",
    "IMAGE_SIZE = 125\n",
    "\n",
    "TRAIN_PATH = \"./data/movida/train/\"\n",
    "\n",
    "TEST_PATH = \"./data/movida/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------df_test---------------------------------------------\n",
    "\n",
    "def read_data(path):\n",
    "    archivos = []\n",
    "    for file in os.listdir(path): \n",
    "            archivos.append(file)            \n",
    "    return np.array(archivos)\n",
    "    \n",
    "archivos_test = read_data(TEST_PATH)\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    'archivo': archivos_test})\n",
    "\n",
    "\n",
    "# -----------------------------------------df_train-----------------------------------------------\n",
    "\n",
    "df_train = pd.read_csv(\"./data/movida/file_target.csv\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train',df_train.head())\n",
    "print('train shape',df_train.shape)\n",
    "print('test',df_test.head())\n",
    "print('test shape',df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data2(df, path, image_size):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        image = imread(os.path.join(path, row['archivo']))\n",
    "        \n",
    "        smallimage = cv2.resize(image, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "        X.append(smallimage)\n",
    "\n",
    "    return np.array(X)\n",
    "\n",
    "X_test = read_data2(df_test, TEST_PATH, IMAGE_SIZE)\n",
    "\n",
    "X_test_norma = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,                                   \n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(df_train,\n",
    "                                                    TRAIN_PATH,\n",
    "                                                    x_col='archivo',\n",
    "                                                    y_col='target',\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'sparse',\n",
    "                                                    target_size = (IMAGE_SIZE, IMAGE_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VGG16\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "                  include_top=False)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "##### FULLY CONNECTED LAYER #####\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = keras.layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = keras.layers.Dense(1000, activation='relu')(x)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and sigmoid activation\n",
    "x = keras.layers.Dense(1000, activation='sigmoid')(x)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = keras.layers.Dense(1000, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = keras.layers.Dense(29, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgghist = model.fit(train_generator,\n",
    "                    epochs = 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_norma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EfficientNetB7\n",
    "\n",
    "import tensorflow.keras.applications as apli\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "base_model = apli.EfficientNetB7(input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "                                 include_top=True,\n",
    "                                 weights=None)\n",
    "\n",
    "\n",
    "base_model.compile(RMSprop(lr=0.0001, decay=1e-6), loss = 'sparse_categorical_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efihist = base_model.fit(train_generator, steps_per_epoch = 100,\n",
    "                    epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = base_model.predict(X_test_norma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_norma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_norma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = predictions.argmax(axis=1)\n",
    "\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "collections.Counter(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['target']=predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = {}\n",
    "\n",
    "for i in range(0,29):\n",
    "    A = df_train[df_train['target_2']==i]['target'].head(1)\n",
    "    B =A.values\n",
    "    series[B[0]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(series.keys())[list(series.values()).index(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_2 = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_number(x):\n",
    "\n",
    "    return list(series.keys())[list(series.values()).index(x)]\n",
    "\n",
    "df_test_2['target'] = df_test_2['target'].apply(change_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_2.to_csv('data/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
